# -*- coding: utf-8 -*-
"""596-final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FYcHlXTkCHnkupfMn8kyMu86-JnoWLa1
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz
!tar -xvf spark-3.0.1-bin-hadoop3.2.tgz
!pip install -q findspark
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.1-bin-hadoop3.2"
import findspark
findspark.init()

https://stackoverflow.com/questions/55240940/error-while-installing-spark-on-google-colab
https://downloads.apache.org/spark/
https://colab.research.google.com/github/asifahmed90/pyspark-ML-in-Colab/blob/master/PySpark_Regression_Analysis.ipynb#scrollTo=v1b8k_OVf2QF
https://colab.research.google.com/drive/1EcotODzgSnLozSH3hDuBfZr06gJXY8I0#scrollTo=XJp8ZI-VzYEz
https://colab.research.google.com/github/rpi-techfundamentals/website_spring_2020/blob/master/content/notebooks/18-big-data/02-intro-spark.ipynb#scrollTo=dYdZQbhYJLlC

from google.colab import files
files.upload()

import pyspark
#sc = pyspark.SparkContext('local[*]')
sc = pyspark.SparkContext.getOrCreate();

import urllib.request, json 
with urllib.request.urlopen("https://jobs.github.com/positions.json?description=developer&lat=37&long=-122") as url:
    data = json.loads(url.read().decode())
    data = data[0]["description"]
    print(data)

candidates = data.strip('<p>').strip('</p>').lower().split()
words = []
skip_words = ['and','or','the','a','of','to','in','on','our','for','with','is']
for i in range(len(candidates)):
  candidates[i] = candidates[i].strip('<p>').strip('</')
  if candidates[i] not in skip_words:
    words.append(candidates[i])
words_rdd = sc.parallelize(words)
word_tuples_rdd = words_rdd.map(lambda x: (x, 1))
#word_tuples_rdd.collect()
#word_tuples_rdd.take(4)
word_counts_rdd = word_tuples_rdd.reduceByKey(lambda x, y: x + y)
word_counts = word_counts_rdd.collect() #The computation is not performed until we request the final result to be collected.
word_counts = sorted(word_counts, key=lambda x:x[1])
word_counts[-3:]